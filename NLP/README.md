## Лабораторные работы по курсу "Обработка естественного языка"

### [Lab1.  Базовая обработка и анализ текста](https://github.com/dunklenichts/ITMO_Courses/blob/main/NLP/Базовая_обработка_и_анализ_текста.ipynb):
1. Обработка текста(отзывов) идет по банку "Тинькофф банк".
2. Произведена предврарительная обработка текста (удаление лишних символов, стемминг/лемматизация, токенизация и т.д.).
3. Составлен топ-10 наиболее часто используемых слов в отзывах.
4. Отзывы разделены на положительные и отрицательные с использованием значения в поле «score» (1,2- негативные, 4,5-позитивные).
5. Составлен топ-10 наиболее часто используемых прилагательных, используемых со словом банк для положительных/отрицательных отзывов.


### [Lab2. Векторное представление текстов](https://github.com/dunklenichts/ITMO_Courses/blob/main/NLP/Векторное_представление_текстов.ipynb):
1. Используются данные из [lab 1](https://github.com/dunklenichts/ITMO_Courses/blob/main/NLP/Базовая_обработка_и_анализ_текста.ipynb).
2. Построены векторные представления отзывов с использованием подходов BoW и TF-IDF c разными параметрами (использование n-gramm, различные пороги по отсечению частотных слов), а также с использованием предобучененных векторов word2vec.
3. Отзывы разделены на положительные и отрицательные можно на основании значения в поле «score» (1,2- негативные, 4,5-позитивные).
4. Отзывы классифицированны на положительные/отрицательные с использованием разных векторных представлений.
5. Проанализирована точность классификации при использовании разных векторных представлений.

   
### [Lab3. Тематическое моделирование](https://github.com/dunklenichts/ITMO_Courses/blob/main/NLP/Тематическое_моделирование.ipynb):
1. Выполните тематическое моделирование отзывов о банковских услугах помощью LDA (библиотека gensim).
2. Найдено оптимальное количество тем в соответствии с метриками:
   1) Perplexity score
   2) Coherence score
3. Визуализированы темы(пакет pyLDAvis).


### [Lab4. Обучение рекурентной нейронной сети](https://github.com/dunklenichts/ITMO_Courses/blob/main/NLP/Обучение_рекурентной_нейронной_сети.ipynb):
1. Проведены два эксперимента-исследования:
    1) изменена архитектура нейронной сети
    2) изменены гиперпараметры
3. Проиллюстрирована зависимость качества классификации от количества эпох обучения.
   1) Perplexity score
   2) Coherence score
4. Показано, как изменились потери/точность при обучении при наличии/отсутствии аргумента с весами классов.
5. Объяснено, какие национальности определяются лучше всего и с чем это может быть связано. Результаты визуализированы.


### [Lab5. Обработка текстовых данных из открытых источников](https://github.com/dunklenichts/ITMO_Courses/blob/main/NLP/Обработка_текстовых_данных_из_открытых_источников.ipynb):
Лабораторная работа направлена на оценку тональности финансовых новостей о компаниях, торгующих на Московской и Санкт-Петербургской биржах
